Bibliographical and Historical Notes 799 
expert system for chemistry (Buchanan and Mitchell, 1978), and later in Mitchell's (1983)   
LEX system, which learns to solve calculus problems. A third influential thread was formed 
by the work of Michalski and colleagues on the AQ series of algorithms, which learned sets 
of logical rules (Michalski, 1969; Michalski et al., 1986). 
EBL had its roots in the techniques used by the STRIPS planner (Pikes et   al., 1972). 
When a plan was constructed, a generalized version of it was saved in a plan library and 
used in later planning as a macro-operator. Similar ideas appeared in Anderson's ACT* 
architecture, under the heading of knowledge compilation (Anderson, 1983), and in the 
SOAR architecture, as chunking (Laird et al., 1986). Schema acquisition (DeJong, 19811, 
analytical generalization (Mitchell, 1982), and constraint-based generalization (Minton, 
1984) were immediate precursors of the rapid growth of interest in EBL stimulated by the 
papers of Mitchell el al. (1986) and DeJong and Mooney (1986). Hirsh (1987) introduced 
the EBL algorithm described in the text, showing how it could be incorporated directly into a 
logic programming system. Van Harmelen  and Bundy (1988) explain EBL as a variant of the 
partial evaluation method used in program analysis systems (Jones et al., 1993). 
Initial enthusiasm for EBL was tempered by Minton's finding (1988) that, without ex-
tensive extra work, EBL could easily slow down a program significantly. Formal probabilistic 
analysis of the expected payoff of EBL can be found in Greiner (1989) and Subramanian  and 
Feldman (1990). An excellent survey of early work on EBL appears in Dietterich (1990). 
Instead of using examples as foci for generalization, one can use them directly to solve 
AIALOGICAL   
new problems, in a process known as analogical reasoning. This form of reasoning ranges 
RE4SONING   
from a form of plausible reasoning based on degree of similarity (Gentner, 1983), through 
a form of deductive inference based on determinations but requiring the participation of the 
- 
example (Davies and Russell, 1987), to a form of "lazy EBL that tailors the direction of 
generalization of the old example to fit the needs of the new problem. This latter form of 
analogical reasoning is found most commonly in case-based  reasoning (Kolodner, 1993) 
and derivational analogy (Veloso and Carbonell, 1993). 
Relevance information in the form of functional dependencies was first developed in 
the database community, where it is used to stmcrure  large sets of attributes into manage-
able subsets. Functional dependencies were used for analogical reasoning by Carbonell 
and Collins (1973) and rediscovered and given a full logical analysis by Davies and Rus-
sell (Davies, 1985; Davies and Russell, 1987). Their role as prior knowledge in inductive 
learning was explored by Russell and Grosof (1987). The equivalence of determinations to 
a restricted-vocabulary hypothesis space was proved in Russell (1988). Learning algorithms 
for determinations and the Unproved  performance obtained by RBDTL were first shown in 
the Focus algorithm, due to Almuallim  and Dietterich (1991). Tadepalli (1993) describes a 
very ingenious algorithm for learning with determinations that shows large improvements in 
learning speed. 
The idea that inductive learning can be performed by inverse deduction can be traced 
to W. S. Jevons (1874), who wrote, "The study both of Formal Logic and of the Theory of 
Probabilities has led me to adopt the opinion that there is no such thing as a distinct method 
of induction as contrasted with deduction, but that induction is simply an inverse employ-
ment of deduction." Computational investigations began with the remarkable Ph.D. thesis by 
