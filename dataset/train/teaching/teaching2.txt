Section 2.3. The Nature of Environments 41   
and potholes. The taxi must also interact with potential and actual passengers. There are also 
some optional choices. The taxi might need to operate in Southern California, where snow 
is seldom a problem, or in Alaska, where it seldom is not. It could always be driving on the 
right, or we might want it to be flexible enough to drive on the left when in Britain or Japan. 
Obviously, the more restricted the environment, the easier the design problem. 
The actuators for an automated taxi include those available to a human driver: control 
over the engine through the accelerator and control over steering and braking. In addition, it 
will need output to a display screen or voice synthesizer to talk back to the passengers, and 
perhaps some way to communicate with other vehicles, politely or otherwise. 
The basic sensors for the taxi will include one or more controllable video cameras so 
that it can see the road; it might augment these with infrared or sonar sensors to detect dis-
tances to other cars and obstacles. To avoid speeding tickets, the taxi should have a speedome-
ter, and Lu  consul  the vehicle properly, especially on curves, it should have an accelerometer. 
To determine the mechanical state of the vehicle, it will need the usual array of engine, fuel, 
and electrical system sensors. Like many human drivers, it might want a global positioning 
system (GPS) so that it doesn't get lost. Finally, it will need a keyboard or microphone for 
the passenger to request a destination. 
In Figure 2.5.   we have sketched the basic PEAS elements for a number of additional 
agent types. Further examples appear in Exercise 2.4. It may come as a surprise to some read- 
ers that our list of agent types includes some programs that operate in the entirely artificial 
environment defined by keyboard input and character output on a screen. "Surely," one might 
say, "this is not a real environment, is it?" In fact, what matters is not the distinction between 
"real" and "artificial" environments, but the complexity of the relationship among the behav-
ior of the agent, the percept sequence generated by the environment, and the performance 
measure. Some "real" environments are actually quite simple. For example, a robot designed 
to inspect parts as they come by on a conveyor belt can make use of a number of simplifying 
assumptions: that the lighting is always just so, that the only thing on the conveyor belt will 
be parts of a kind that it knows about, and that only two actions (accept or reject) are possible. 
SCMYARE   AGENT In contrast, some software agents (or software robots or softhots)  exist in rich, unlitm- 
S0=TBOT ited domains. Imagine a softbot Weh  site operator designed to scan Internet news sources and 
show the interesting items to its users, while selling advertising space to generate revenue. 
To do well, that operator will need some natural language processing abilities, it will need 
to learn what each user and advertiser is interested in, and it will need to change its plans 
dynamically—for  example, when the connection for one news source goes down or when a 
new one comes online. The Internet is an environment whose complexity rivals that of the 
physical world and whose inhabitants include many artificial and human agents. 
2.3.2 Properties of task environments 
The range of task environments that might arise in AI is obviously vast. We can, however, 
identify a fairly small number of dimensions along which task environments can be catego- 
rized. These dimensions determine, to a large extent, the appropriate  agent design and the 
applicability of each of the principal families of techniques for agent implementation. First, 
